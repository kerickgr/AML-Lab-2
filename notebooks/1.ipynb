{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа: Мета-обучение\n",
    "## Часть 2: Оптимизация гиперпараметров\n",
    "\n",
    "**Цель:** Исследовать различные методы оптимизации гиперпараметров и их влияние на качество моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "import warnings\n",
    "import time\n",
    "import optuna\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Описание выбранного набора данных, методов обучения и пространства гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор датасета\n",
    "\n",
    "Для экспериментов по оптимизации гиперпараметров мы используем синтетический датасет, созданный с помощью `make_classification`. Это позволит нам контролировать сложность задачи и получать воспроизводимые результаты.\n",
    "\n",
    "**Характеристики датасета:**\n",
    "- 1000 образцов\n",
    "- 20 признаков (15 информативных, 5 избыточных)\n",
    "- 3 класса\n",
    "- 5% шума\n",
    "\n",
    "### Выбор алгоритма\n",
    "\n",
    "Для оптимизации мы используем **Random Forest Classifier**, так как он:\n",
    "- Имеет много гиперпараметров для настройки\n",
    "- Широко используется на практике\n",
    "- Устойчив к переобучению\n",
    "\n",
    "### Пространство гиперпараметров\n",
    "\n",
    "| Параметр | Диапазон | Описание |\n",
    "|----------|----------|----------|\n",
    "| `n_estimators` | 50-300 | Количество деревьев |\n",
    "| `max_depth` | 5-50 | Максимальная глубина |\n",
    "| `min_samples_split` | 2-20 | Минимальное число образцов для разделения |\n",
    "| `min_samples_leaf` | 1-10 | Минимальное число образцов в листе |\n",
    "| `max_features` | 0.1-0.9 | Доля признаков для каждого дерева |\n",
    "| `bootstrap` | [True, False] | Использовать бутстреп |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Создание датасета\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=3,\n",
    "    flip_y=0.05,  # 5% шума\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Датасет создан:\")\n",
    "print(f\"  Количество образцов: {X.shape[0]}\")\n",
    "print(f\"  Количество признаков: {X.shape[1]}\")\n",
    "print(f\"  Количество классов: {len(np.unique(y))}\")\n",
    "\n",
    "# Разделение на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nОбучающая выборка: {X_train.shape[0]} образцов\")\n",
    "print(f\"Тестовая выборка: {X_test.shape[0]} образцов\")\n",
    "\n",
    "# Базовый классификатор (без оптимизации)\n",
    "baseline_rf = RandomForestClassifier(random_state=42)\n",
    "baseline_rf.fit(X_train, y_train)\n",
    "baseline_pred = baseline_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nБазовый Random Forest (параметры по умолчанию):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, baseline_pred):.4f}\")\n",
    "print(f\"  F1-score (weighted): {f1_score(y_test, baseline_pred, average='weighted'):.4f}\")\n",
    "print(f\"  Balanced accuracy: {balanced_accuracy_score(y_test, baseline_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Оптимизация гиперпараметров различными методами\n",
    "\n",
    "### 1. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Пространство поиска для Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(5, 50),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': uniform(0.1, 0.8),  # от 0.1 до 0.9\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Random Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='balanced_accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Запуск Random Search...\")\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "random_time = time.time() - start_time\n",
    "\n",
    "print(f\"Random Search завершен за {random_time:.2f} секунд\")\n",
    "print(f\"Лучшие параметры: {random_search.best_params_}\")\n",
    "print(f\"Лучшая точность (CV): {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Оценка на тесте\n",
    "random_pred = random_search.predict(X_test)\n",
    "random_test_acc = balanced_accuracy_score(y_test, random_pred)\n",
    "print(f\"Точность на тесте: {random_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация результатов Random Search\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# 1. Сходимость по итерациям\n",
    "ax1 = axes[0, 0]\n",
    "results_df_sorted = results_df.sort_values('mean_test_score', ascending=False)\n",
    "ax1.plot(range(1, len(results_df_sorted) + 1), \n",
    "         results_df_sorted['mean_test_score'].values, 'bo-', alpha=0.6)\n",
    "ax1.axhline(y=results_df_sorted['mean_test_score'].iloc[0], \n",
    "            color='r', linestyle='--', label='Лучший результат')\n",
    "ax1.set_xlabel('Итерация (отсортировано по качеству)')\n",
    "ax1.set_ylabel('Средняя точность (CV)')\n",
    "ax1.set_title('Random Search: Распределение результатов')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Гистограмма результатов\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(results_df['mean_test_score'], bins=20, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=results_df['mean_test_score'].mean(), \n",
    "            color='g', linestyle='--', label=f'Среднее: {results_df[\"mean_test_score\"].mean():.3f}')\n",
    "ax2.axvline(x=results_df['mean_test_score'].max(), \n",
    "            color='r', linestyle='--', label=f'Макс: {results_df[\"mean_test_score\"].max():.3f}')\n",
    "ax2.set_xlabel('Точность')\n",
    "ax2.set_ylabel('Частота')\n",
    "ax2.set_title('Random Search: Распределение результатов')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Время vs качество\n",
    "ax3 = axes[0, 2]\n",
    "ax3.scatter(results_df['mean_fit_time'], results_df['mean_test_score'], \n",
    "            alpha=0.6, c='blue')\n",
    "ax3.set_xlabel('Время обучения (сек)')\n",
    "ax3.set_ylabel('Точность')\n",
    "ax3.set_title('Random Search: Время vs Качество')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Важность n_estimators\n",
    "ax4 = axes[1, 0]\n",
    "ax4.scatter(results_df['param_n_estimators'], results_df['mean_test_score'], \n",
    "            alpha=0.6, c='green')\n",
    "ax4.set_xlabel('n_estimators')\n",
    "ax4.set_ylabel('Точность')\n",
    "ax4.set_title('Влияние n_estimators')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Важность max_depth\n",
    "ax5 = axes[1, 1]\n",
    "ax5.scatter(results_df['param_max_depth'], results_df['mean_test_score'], \n",
    "            alpha=0.6, c='red')\n",
    "ax5.set_xlabel('max_depth')\n",
    "ax5.set_ylabel('Точность')\n",
    "ax5.set_title('Влияние max_depth')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Важность min_samples_split\n",
    "ax6 = axes[1, 2]\n",
    "ax6.scatter(results_df['param_min_samples_split'], results_df['mean_test_score'], \n",
    "            alpha=0.6, c='purple')\n",
    "ax6.set_xlabel('min_samples_split')\n",
    "ax6.set_ylabel('Точность')\n",
    "ax6.set_title('Влияние min_samples_split')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Random Search Optimization Results', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optuna (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Целевая функция для Optuna\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_float('max_features', 0.1, 0.9),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, \n",
    "                             scoring='balanced_accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "print(\"Запуск Optuna...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Создаем исследование\n",
    "study = optuna.create_study(direction='maximize', study_name='rf_optimization')\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "optuna_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nOptuna завершен за {optuna_time:.2f} секунд\")\n",
    "print(f\"Лучшие параметры: {study.best_params}\")\n",
    "print(f\"Лучшая точность (CV): {study.best_value:.4f}\")\n",
    "\n",
    "# Оценка на тесте\n",
    "best_rf = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "optuna_pred = best_rf.predict(X_test)\n",
    "optuna_test_acc = balanced_accuracy_score(y_test, optuna_pred)\n",
    "print(f\"Точность на тесте: {optuna_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация результатов Optuna\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. История оптимизации\n",
    "ax1 = axes[0, 0]\n",
    "optuna_history = pd.DataFrame({\n",
    "    'trial': range(len(study.trials)),\n",
    "    'value': [t.value for t in study.trials]\n",
    "})\n",
    "ax1.plot(optuna_history['trial'], optuna_history['value'], 'b-', alpha=0.5, label='Все попытки')\n",
    "ax1.plot(optuna_history['trial'], \n",
    "         optuna_history['value'].cummax(), \n",
    "         'r-', linewidth=2, label='Лучший результат')\n",
    "ax1.set_xlabel('Номер попытки')\n",
    "ax1.set_ylabel('Точность')\n",
    "ax1.set_title('Optuna: История оптимизации')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Распределение результатов\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(optuna_history['value'], bins=20, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=optuna_history['value'].mean(), \n",
    "            color='g', linestyle='--', label=f'Среднее: {optuna_history[\"value\"].mean():.3f}')\n",
    "ax2.axvline(x=optuna_history['value'].max(), \n",
    "            color='r', linestyle='--', label=f'Макс: {optuna_history[\"value\"].max():.3f}')\n",
    "ax2.set_xlabel('Точность')\n",
    "ax2.set_ylabel('Частота')\n",
    "ax2.set_title('Optuna: Распределение результатов')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Важность параметров\n",
    "ax3 = axes[0, 2]\n",
    "importance = optuna.importance.get_param_importances(study)\n",
    "params = list(importance.keys())\n",
    "values = list(importance.values())\n",
    "ax3.barh(range(len(params)), values, color='coral', alpha=0.7)\n",
    "ax3.set_yticks(range(len(params)))\n",
    "ax3.set_yticklabels(params)\n",
    "ax3.set_xlabel('Важность')\n",
    "ax3.set_title('Optuna: Важность гиперпараметров')\n",
    "ax3.invert_yaxis()\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Влияние n_estimators\n",
    "ax4 = axes[1, 0]\n",
    "n_estimators_values = [t.params['n_estimators'] for t in study.trials]\n",
    "ax4.scatter(n_estimators_values, optuna_history['value'], alpha=0.6)\n",
    "ax4.set_xlabel('n_estimators')\n",
    "ax4.set_ylabel('Точность')\n",
    "ax4.set_title('Влияние n_estimators')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Влияние max_depth\n",
    "ax5 = axes[1, 1]\n",
    "max_depth_values = [t.params['max_depth'] for t in study.trials]\n",
    "ax5.scatter(max_depth_values, optuna_history['value'], alpha=0.6, color='green')\n",
    "ax5.set_xlabel('max_depth')\n",
    "ax5.set_ylabel('Точность')\n",
    "ax5.set_title('Влияние max_depth')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Влияние min_samples_split\n",
    "ax6 = axes[1, 2]\n",
    "min_samples_split_values = [t.params['min_samples_split'] for t in study.trials]\n",
    "ax6.scatter(min_samples_split_values, optuna_history['value'], alpha=0.6, color='purple')\n",
    "ax6.set_xlabel('min_samples_split')\n",
    "ax6.set_ylabel('Точность')\n",
    "ax6.set_title('Влияние min_samples_split')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Optuna Bayesian Optimization Results', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Пространство поиска для Hyperopt\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 301)),\n",
    "    'max_depth': hp.choice('max_depth', range(5, 51)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 21)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),\n",
    "    'max_features': hp.uniform('max_features', 0.1, 0.9),\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False])\n",
    "}\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    \"\"\"Целевая функция для Hyperopt\"\"\"\n",
    "    # Преобразование параметров\n",
    "    rf_params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'min_samples_split': int(params['min_samples_split']),\n",
    "        'min_samples_leaf': int(params['min_samples_leaf']),\n",
    "        'max_features': params['max_features'],\n",
    "        'bootstrap': params['bootstrap'],\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**rf_params)\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, \n",
    "                             scoring='balanced_accuracy')\n",
    "    \n",
    "    # Hyperopt минимизирует, поэтому возвращаем отрицательную точность\n",
    "    return {'loss': -scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "print(\"Запуск Hyperopt...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Запуск оптимизации\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=hyperopt_objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "hyperopt_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nHyperopt завершен за {hyperopt_time:.2f} секунд\")\n",
    "print(f\"Лучшие параметры: {best}\")\n",
    "\n",
    "# Преобразование лучших параметров\n",
    "best_hyperopt_params = {\n",
    "    'n_estimators': int(best['n_estimators']),\n",
    "    'max_depth': int(best['max_depth']),\n",
    "    'min_samples_split': int(best['min_samples_split']),\n",
    "    'min_samples_leaf': int(best['min_samples_leaf']),\n",
    "    'max_features': best['max_features'],\n",
    "    'bootstrap': best['bootstrap']\n",
    "}\n",
    "\n",
    "print(f\"Лучшая точность (CV): {-min([t['result']['loss'] for t in trials.trials]):.4f}\")\n",
    "\n",
    "# Оценка на тесте\n",
    "best_hyperopt_rf = RandomForestClassifier(**best_hyperopt_params, random_state=42)\n",
    "best_hyperopt_rf.fit(X_train, y_train)\n",
    "hyperopt_pred = best_hyperopt_rf.predict(X_test)\n",
    "hyperopt_test_acc = balanced_accuracy_score(y_test, hyperopt_pred)\n",
    "print(f\"Точность на тесте: {hyperopt_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация результатов Hyperopt\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Извлечение результатов\n",
    "hyperopt_losses = [-t['result']['loss'] for t in trials.trials]\n",
    "hyperopt_trials = range(len(hyperopt_losses))\n",
    "\n",
    "# 1. История оптимизации\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(hyperopt_trials, hyperopt_losses, 'b-', alpha=0.5, label='Все попытки')\n",
    "ax1.plot(hyperopt_trials, np.maximum.accumulate(hyperopt_losses), \n",
    "         'r-', linewidth=2, label='Лучший результат')\n",
    "ax1.set_xlabel('Номер попытки')\n",
    "ax1.set_ylabel('Точность')\n",
    "ax1.set_title('Hyperopt: История оптимизации')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Распределение результатов\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(hyperopt_losses, bins=20, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=np.mean(hyperopt_losses), \n",
    "            color='g', linestyle='--', label=f'Среднее: {np.mean(hyperopt_losses):.3f}')\n",
    "ax2.axvline(x=np.max(hyperopt_losses), \n",
    "            color='r', linestyle='--', label=f'Макс: {np.max(hyperopt_losses):.3f}')\n",
    "ax2.set_xlabel('Точность')\n",
    "ax2.set_ylabel('Частота')\n",
    "ax2.set_title('Hyperopt: Распределение результатов')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Сравнение времени\n",
    "ax3 = axes[1, 0]\n",
    "methods = ['Random Search', 'Optuna', 'Hyperopt']\n",
    "times = [random_time, optuna_time, hyperopt_time]\n",
    "colors = ['blue', 'green', 'orange']\n",
    "bars = ax3.bar(methods, times, color=colors, alpha=0.7)\n",
    "ax3.set_ylabel('Время (секунды)')\n",
    "ax3.set_title('Сравнение времени оптимизации')\n",
    "for bar, time_val in zip(bars, times):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "             f'{time_val:.1f}s', ha='center', fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Сравнение качества\n",
    "ax4 = axes[1, 1]\n",
    "test_scores = [\n",
    "    random_test_acc,\n",
    "    optuna_test_acc,\n",
    "    hyperopt_test_acc,\n",
    "    balanced_accuracy_score(y_test, baseline_pred)  # Baseline\n",
    "]\n",
    "methods_with_baseline = ['Random Search', 'Optuna', 'Hyperopt', 'Baseline']\n",
    "colors2 = ['blue', 'green', 'orange', 'gray']\n",
    "bars2 = ax4.bar(methods_with_baseline, test_scores, color=colors2, alpha=0.7)\n",
    "ax4.set_ylabel('Точность на тесте')\n",
    "ax4.set_title('Сравнение качества на тестовой выборке')\n",
    "ax4.set_ylim([0.7, 1.0])\n",
    "for bar, score in zip(bars2, test_scores):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "             f'{score:.3f}', ha='center', fontsize=10)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Hyperopt Optimization Results', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ сходимости методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Random Search сходимость\n",
    "ax1 = axes[0]\n",
    "rs_cummax = results_df.sort_values('rank_test_score')['mean_test_score'].values\n",
    "ax1.plot(range(1, len(rs_cummax) + 1), rs_cummax, 'b-', linewidth=2, label='Random Search')\n",
    "ax1.set_xlabel('Количество попыток')\n",
    "ax1.set_ylabel('Лучшая точность')\n",
    "ax1.set_title('Random Search: Сходимость')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Optuna сходимость\n",
    "ax2 = axes[1]\n",
    "optuna_cummax = np.maximum.accumulate([t.value for t in study.trials])\n",
    "ax2.plot(range(1, len(optuna_cummax) + 1), optuna_cummax, 'g-', linewidth=2, label='Optuna')\n",
    "ax2.set_xlabel('Количество попыток')\n",
    "ax2.set_ylabel('Лучшая точность')\n",
    "ax2.set_title('Optuna: Сходимость')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Hyperopt сходимость\n",
    "ax3 = axes[2]\n",
    "hyperopt_cummax = np.maximum.accumulate(hyperopt_losses)\n",
    "ax3.plot(range(1, len(hyperopt_cummax) + 1), hyperopt_cummax, 'orange', linewidth=2, label='Hyperopt')\n",
    "ax3.set_xlabel('Количество попыток')\n",
    "ax3.set_ylabel('Лучшая точность')\n",
    "ax3.set_title('Hyperopt: Сходимость')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "plt.suptitle('Сравнение сходимости методов оптимизации', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Объединенный график\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(rs_cummax) + 1), rs_cummax, 'b-', linewidth=2, label='Random Search')\n",
    "plt.plot(range(1, len(optuna_cummax) + 1), optuna_cummax, 'g-', linewidth=2, label='Optuna')\n",
    "plt.plot(range(1, len(hyperopt_cummax) + 1), hyperopt_cummax, 'orange', linewidth=2, label='Hyperopt')\n",
    "plt.axhline(y=random_test_acc, color='b', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=optuna_test_acc, color='g', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=hyperopt_test_acc, color='orange', linestyle='--', alpha
