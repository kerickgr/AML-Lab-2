{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа: Мета-обучение\n",
    "## Шаги 3-4: Оценка алгоритмов и построение мета-набора\n",
    "\n",
    "**Цель:** Оценить базовые алгоритмы на каждом датасете и определить лучший"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.algorithms.base_learners import BaseLearners\n",
    "from src.algorithms.evaluation import AlgorithmEvaluator\n",
    "from src.data.collector import OpenMLCollector\n",
    "from src.visualization.plots import MetaVisualizer\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Загружаем список датасетов\n",
    "datasets_df = pd.read_csv('../data/raw/dataset_list.csv')\n",
    "print(f\"Загружено {len(datasets_df)} датасетов\")\n",
    "\n",
    "# Загружаем мета-признаки (если уже есть)\n",
    "try:\n",
    "    meta_df = pd.read_csv('../data/processed/meta_features_raw.csv')\n",
    "    print(f\"Загружены мета-признаки для {len(meta_df)} датасетов\")\n",
    "except:\n",
    "    print(\"Мета-признаки не найдены, будут извлечены позже\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Выбор алгоритмов для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Выбираем 3 алгоритма с разной природой\n",
    "learners = BaseLearners(['LogisticRegression', 'RandomForest', 'KNN'])\n",
    "\n",
    "print(\"Выбранные алгоритмы:\")\n",
    "for name, algo in learners.get_all_algorithms().items():\n",
    "    print(f\"  - {name}: {algo.__class__.__name__}\")\n",
    "\n",
    "# Создаем оценщик\n",
    "evaluator = AlgorithmEvaluator(\n",
    "    learners.get_all_algorithms(),\n",
    "    cv_folds=5,\n",
    "    scoring='balanced_accuracy'\n",
    ")\n",
    "\n",
    "visualizer = MetaVisualizer(save_dir='../results/visualizations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Тестирование на примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Загружаем тестовый датасет\n",
    "collector = OpenMLCollector(use_cache=True)\n",
    "X, y = collector.download_dataset(61)  # Iris\n",
    "\n",
    "print(f\"Тестовый датасет: {X.shape[0]} объектов, {X.shape[1]} признаков, {len(np.unique(y))} классов\")\n",
    "\n",
    "# Оцениваем\n",
    "scores = evaluator.evaluate_all(X, y)\n",
    "best_algo, best_score = evaluator.get_best_algorithm(X, y)\n",
    "\n",
    "print(\"\\nРезультаты оценки:\")\n",
    "for algo, score in scores.items():\n",
    "    print(f\"  {algo}: {score:.4f}\")\n",
    "print(f\"\\nЛучший алгоритм: {best_algo} с точностью {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Массовая оценка алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Для демонстрации возьмем первые 10 датасетов\n",
    "# В реальном проекте будет 350\n",
    "sample_datasets = datasets_df.head(10)\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in tqdm(sample_datasets.iterrows(), total=len(sample_datasets)):\n",
    "    dataset_id = row['did']\n",
    "    \n",
    "    try:\n",
    "        X, y = collector.download_dataset(dataset_id)\n",
    "        \n",
    "        if X is not None:\n",
    "            scores = evaluator.evaluate_all(X, y)\n",
    "            \n",
    "            result = {\n",
    "                'dataset_id': dataset_id,\n",
    "                'dataset_name': row['name'],\n",
    "                'best_algorithm': max(scores, key=scores.get),\n",
    "                **{f'score_{k}': v for k, v in scores.items()}\n",
    "            }\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в датасете {dataset_id}: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nОценено {len(results_df)} датасетов\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Анализ результатов\n",
    "print(\"\\nРаспределение лучших алгоритмов:\")\n",
    "best_counts = results_df['best_algorithm'].value_counts()\n",
    "print(best_counts)\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Распределение лучших алгоритмов\n",
    "best_counts.plot(kind='bar', ax=axes[0], color='coral', alpha=0.7)\n",
    "axes[0].set_xlabel('Алгоритм')\n",
    "axes[0].set_ylabel('Количество датасетов')\n",
    "axes[0].set_title('Распределение лучших алгоритмов')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Производительность алгоритмов\n",
    "score_cols = [c for c in results_df.columns if c.startswith('score_')]\n",
    "score_data = []\n",
    "for col in score_cols:\n",
    "    for score in results_df[col].dropna():\n",
    "        score_data.append({'Algorithm': col.replace('score_', ''), 'Score': score})\n",
    "\n",
    "score_df = pd.DataFrame(score_data)\n",
    "sns.boxplot(data=score_df, x='Algorithm', y='Score', ax=axes[1])\n",
    "axes[1].set_title('Распределение производительности алгоритмов')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Построение мета-набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Объединяем мета-признаки с результатами\n",
    "if 'meta_df' in locals() and not meta_df.empty and not results_df.empty:\n",
    "    meta_dataset = pd.merge(meta_df, results_df[['dataset_id', 'best_algorithm']], on='dataset_id')\n",
    "    print(f\"Мета-набор данных: {meta_dataset.shape[0]} строк, {meta_dataset.shape[1]} колонок\")\n",
    "    \n",
    "    # Сохраняем\n",
    "    meta_dataset.to_csv('../results/meta_dataset/meta_dataset_complete.csv', index=False)\n",
    "    print(\"Мета-набор сохранен в ../results/meta_dataset/meta_dataset_complete.csv\")\n",
    "else:\n",
    "    print(\"Недостаточно данных для построения мета-набора\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Выводы по шагам 3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ВЫВОДЫ ПО ШАГАМ 3-4: ОЦЕНКА АЛГОРИТМОВ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "1. ВЫБРАНЫ АЛГОРИТМЫ:\n",
    "   - Logistic Regression (линейная модель)\n",
    "   - Random Forest (ансамблевая модель)\n",
    "   - KNN (модель на основе расстояний)\n",
    "\n",
    "2. МЕТРИКА ОЦЕНКИ: balanced_accuracy (устойчива к дисбалансу классов)\n",
    "\n",
    "3. ВАЛИДАЦИЯ: 5-кратная стратифицированная кросс-валидация\n",
    "\n",
    "4. РЕЗУЛЬТАТЫ:\n",
    "   - Оценено {len(results_df)} датасетов\n",
    "   - Распределение лучших алгоритмов:\n",
    "{best_counts.to_string()}\n",
    "\n",
    "5. МЕТА-НАБОР ДАННЫХ СОЗДАН:\n",
    "   - Каждая строка: датасет\n",
    "   - Признаки: мета-признаки\n",
    "   - Целевая переменная: лучший алгоритм\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}